---
title: "Qualifying for a Loan"
subtitle: "DATA 450 Capstone"
author: "Thomas Ortega"
date: today
bibliography: references.bib
number-sections: true
format:
  pdf: default
jupyter: python3
---

# Introduction
[This section should contain background and introduction to your general topic.] 

Loans are a fundamental aspect of not only the United States' economy but economies world wide. Loans provide funding to people lacking the current resources to consolidate debt, buy a house, buy a car, open a business, and any transaction that requires money. To make a profit, loans are expected to be paid back with interest. Companies want to know which applicants that apply for a loan will pay it back. Selecting a string of clients that default would spell disaster for the loaner. With teams of analysts, they build models to identify candidates. People on the outside of these lending companies want to know what traits make a candidate more or less likely to receive a loan. Using a dataset containing variables describing candidates that are accepted or rejected, the project will dig into the data to find insights and build visuals describing the population of both accepted and rejected applicants. Also, the project entails building a model that uses the features inherent in the dataset to predict whether a customer is accepted or rejected. The data belongs to a bank called LendingClub. LendingClub is an FDIC-insured bank that provides various loans.

# Dataset

[In this section, desribe the dataset(s). This includes things like where you
obtained the dataset. Include a full citation, as specified 
[here](https://guides.lib.umich.edu/c.php?g=282964&p=3285995). Describe how the
data was obtained by the data owner/curator, as best as you can. List the 
variables that you plan to use in your analysis, for example:

* weight: The patient's weight (kg)
* sex: The patient's sex, male or female
* age: The patient's age (months)

]


The data comes from a Kaggle dataset @geor19 and it is split into two separate csv files: one for accepted applicants, and one for rejected applicants. The accepted file contains over two million rows and one hundred and fifty-one columns. The rejected data contains over twenty-seven million rows and nine columns. The Kaggle posting does not efficiently provide a data dictionary for every column; however, another post in Kaggle provides information on each column @chan18. As stated in the introduction, the data was pulled from LendingClub. LendingClub no longer has the option to download this data.

#### Variables Under Examination:

* Amount Requested: The total amount requested by the borrower.
* Loan Title: The reason for applying for the loan.
* Risk Score: The borrower's FICO score.
* Debt-To-Income Ratio: A ratio calculated using the borrower's total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower's self-reported monthly income.
* Zip Code: The first 3 numbers of the zip code provided by the borrower in the loan application.
* State: The state provided by the borrower in the loan application.
* Employment Length: Possible values are between 0 and 10 where 0 is less than one year and 10 means ten or more years.
* Interest Rate: Interest rate on the loan.
* Employee Title: The job title supplied by the borrower.
* Funded Amount: The total amount committed to that loan.
* Hardship Flag: Flags whether or not the borrower is on a hardship plan.
* Publicly Recorded Bankruptcies: Number of public record bankruptcies.
* Home Ownership: Home ownership status provided by the borrower.
* Loan Status: Current status of the loan.
* Application Type: Indicates whether the loan is an individual application or a joint application with two co-borrowers.
* Issue Date: The month the loan was funded.
* Last Payment Date: Last month payment was received.
* Policy Code: Publicly available policy_code=1 new products not publicly available policy_code=2

# Data Acquisition and Processing

[In this section, if applicable, describe how you will obtain the data (if it's
anything more complicated than a simple download). Discuss what data 
processing steps will be needed, such as recoding variables, data cleaning,
data tidying, imputing missing values, etc. See sections 1c, 1d, 1e in the 
"Good Enough Practices" paper.]

The data will be downloaded from the Kaggle dataset and extracted using 7-Zip. The data is too large and too uneven to analyze, so there will be a random selection of one hundred thousand rows from each file to be used for analysis. The cleaning portion will be split into multiple sections. The first step in the cleaning is identifying which variables correspond to both rejected and accepted files. Columns with a significant percentage of null values will be dropped from their dataset. The next step is matching the variables corresponding to both rejected and accepted tables. When a match is found, both variables will be renamed to have the same name. Then, any other column names that appear vague will be renamed. Next, the data will be checked to determine if each column is the right data type. After, we will use different imputation techniques to fill in missing values based on the data type. Each step will have its own documentation to explain the methods used and why it was chosen. All columns appear to be tidy, so there is no need to alter column values besides for imputation. Once the data looks clean, it will be used for two aspects of the project. The first aspect considers analysis of only accepted customer data, and a copy of the cleaned accepted data will be made. The other aspect looks to combine accepted and rejected applicants based on the previously defined corresponding columns to be used in machine learning algorithms. The modeling will be done with an 80-20 split of train and testing data.


# Research Questions and Methodology

[In this section, list each of the questions you will explore. Following each
question, provide a detailed and specific plan for how you plan to answer the 
question. Include the specific steps you will take, what form the answer will 
take (a number? table? visualization? model? Give all the specifics), and 
estimate how many hours each question will take to complete.]

1. Is employment length correlated to the acceptance of loans? To answer this, a grouped bar plot will be made with each employment length category representing two bars. One bar will represent the count of accepted observations and the other will be the count of rejected obervations. The two groups (rejected and accepted) will have different colors. (2.5 hours)

2. Is there a tendency for specific loans to be given during a specific months? To answer this, a rose plot will be constructed using the twelve months. The legend will represent the top five most frequent loans. Each loan will have a unique color. (1.5 hours)

3. What is the frequency of accepted and rejected loans throughout the United States? To answer this, a map using geospatial data of the U.S. will plotted and matched with the first three digits of the applicant's zip code. A map using the states can also be built, but the main visual will use the zip code. Two graphs will be made splitting rejected and accepted applicants. The frequency will be recorded as a single gradient of a color with a higher count representing a darker gradient. A legend will be provided to indicate the gradient and the number that the different colors represent. (3.5 hours)

4. Does the ratio of amount funded to amount requested change based on hardship flag, home ownership, and application type? To answer this, I will build a tree diagram that builds branches based on the outcome of the three chosen columns. Each level of the tree will be colored differently. The results of the tree will be inputted as the average of the grouped ratios. (3 hours)

5. Does an applicant's FICO score change the interest rate they receive? What about the funding-requested ratio? To answer this, an area chart will be used to measure the count of applicants and split by their FICO score grouping. The x-axis will be either the interest rate or funding-requested ratio. Their will be two graphs, one for each x-axis variable. The FICO score groups will each have their own color along a single gradient and a legend will specify. (3 hours)

6. Is there a bound to Debt-To-Income ratio so that customers who are below a certain limit cannot be accepted? To answer this, a histogram will be built to represent the DTI ratio of both rejected and accepted applicants. If there is a noticeable drop in acceptance, that observation may indicate a minimum acceptance. (1.5 hours)

7. Using the matching features between accepted and rejected data, is it possible to effectively predict whether a candidate will be accepted or rejected? 

# Work plan

[Fill in the list below with a plan for what you will do each week. You should
have around 7 hours worth of work each week. Writing work counts. Several tasks
have already been filled in for you.]

**Week 4 (2/6 - 2/12):** [Just an example: 

* Data tidying and recoding (4 hours)
* Question 2 (4 hours).]

**Week 5 (2/13 - 2/19):**

**Week 6 (2/20 - 2/26):**

**Week 7 (2/27 - 3/5):**

* Presentation prep and practice (4 hours)

**Week 8 (3/6 - 3/12):** *Presentations in class on Thurs 3/9.*

* Presentation peer review (1.5 hours)

**Week 9 (3/20 - 3/26):**

* Poster prep (4 hours)

**Week 10 (3/27 - 4/2):** *Poster Draft 1 due Monday 3/27*.
*Peer feedback due Thursday 3/30*.

* Peer feedback (2.5 hours)

* Poster revisions (2 hours)

**Week 11 (4/3 - 4/9):** *Poster Draft 2 due Monday 4/3*.
*Final Poster due Saturday 4/8*.

* Poster revisions (1 hour).

**Week 12 (4/10 - 4/16):**

**Week 13 (4/17 - 4/23):** [All project work should be done by the end of this 
week. The remaining time will be used for writing up and presenting your 
results.]

* Draft blog post (5 hours).

**Week 14 (4/24 - 4/30):** *Blog post draft 1 due Monday 4/24. Peer feedback due Thursday 4/27. Blog post draft 2 due Sunday 4/30*. 

* Peer feedback (2.5 hours)
* Blog post revisions (2 hours)
* [Do not schedule any other tasks for this week.]

**Week 15 (5/1 - 5/7):**  *Final blog post due Tuesday 5/2*.

* Final presentation prep and practice.

* [Do not schedule any other tasks for this week.]

**Final Exam Week (5/8):** *Final Presentations during final exam slot,
Monday May 9th 3:20-6:40pm.* [Do not schedule any other tasks for this week.]


Here's an example of citing a source [see @phil99, pp. 33-35]. Be sure the source information is entered in "BibTeX" form in the `references.bib` file.

# References

[The bibliography will automatically get generated. Any sources you
cite in the document will be included. Other entries in the `.bib` file
will not be included.]
