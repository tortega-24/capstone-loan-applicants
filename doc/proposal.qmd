---
title: "Qualifying for a Loan"
subtitle: "DATA 450 Capstone"
author: "Thomas Ortega"
date: today
bibliography: references.bib
number-sections: true
format:
  pdf: default
jupyter: python3
---

# Introduction

Loans are a fundamental aspect of not only the United States' economy but economies world wide. Loans provide funding to people lacking the current resources to consolidate debt, buy a house, buy a car, open a business, and any transaction that requires money. To make a profit, loans are expected to be paid back with interest. Companies want to know which applicants that apply for a loan will pay it back. Selecting a string of clients that default would spell disaster for the loaner. With teams of analysts, they build models to identify candidates. People on the outside of these lending companies want to know what traits make a candidate more or less likely to receive a loan. Using a dataset containing variables describing candidates that are accepted or rejected, the project will dig into the data to find insights and build visuals describing the population of both accepted and rejected applicants. Also, the project entails building a model that uses the features inherent in the dataset to predict whether a customer is accepted or rejected. The data belongs to a bank called LendingClub. LendingClub is an FDIC-insured bank that provides various loans.

# Dataset

The data comes from a Kaggle dataset @geor19 and it is split into two separate csv files: one for accepted applicants, and one for rejected applicants. The accepted file contains over two million rows and one hundred and fifty-one columns. The rejected data contains over twenty-seven million rows and nine columns. The Kaggle posting does not efficiently provide a data dictionary for every column; however, another post in Kaggle provides information on each column @chan18. As stated in the introduction, the data was pulled from LendingClub. LendingClub no longer has the option to download this data.

#### Variables Under Examination:

* Amount Requested: The total amount requested by the borrower.
* Loan Title: The reason for applying for the loan.
* Risk Score: The borrower's FICO score.
* Debt-To-Income Ratio: A ratio calculated using the borrower's total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower's self-reported monthly income.
* Zip Code: The first 3 numbers of the zip code provided by the borrower in the loan application.
* State: The state provided by the borrower in the loan application.
* Employment Length: Possible values are between 0 and 10 where 0 is less than one year and 10 means ten or more years.
* Interest Rate: Interest rate on the loan.
* Employee Title: The job title supplied by the borrower.
* Funded Amount: The total amount committed to that loan.
* Hardship Flag: Flags whether or not the borrower is on a hardship plan.
* Home Ownership: Home ownership status provided by the borrower.
* Loan Status: Current status of the loan.
* Application Type: Indicates whether the loan is an individual application or a joint application with two co-borrowers.
* Issue Date: The month the loan was funded.
* Policy Code: Publicly available policy_code=1 new products not publicly available policy_code=2

# Data Acquisition and Processing

The data will be downloaded from the Kaggle dataset and extracted using 7-Zip. The data is too large and too uneven to analyze, so there will be a random selection of one hundred thousand rows from each file to be used for analysis. The cleaning portion will be split into multiple sections. The first step in the cleaning is identifying which variables correspond to both rejected and accepted files. Columns with a significant percentage of null values will be dropped from their dataset. The next step is matching the variables corresponding to both rejected and accepted tables. When a match is found, both variables will be renamed to have the same name. Then, any other column names that appear vague will be renamed. Next, the data will be checked to determine if each column is the right data type. After, we will use different imputation techniques to fill in missing values based on the data type. Each step will have its own documentation to explain the methods used and why it was chosen. All columns appear to be tidy, so there is no need to alter column values besides for imputation. Once the data looks clean, it will be used for two aspects of the project. The first aspect considers analysis of only accepted customer data, and a copy of the cleaned accepted data will be made. The other aspect looks to combine accepted and rejected applicants based on the previously defined corresponding columns to be used in machine learning algorithms. The modeling will be done with an 80-20 split of train and testing data.


# Research Questions and Methodology

1. Is employment length correlated to the acceptance of loans? To answer this, a grouped bar plot will be made with each employment length category representing two bars. One bar will represent the count of accepted observations and the other will be the count of rejected obervations. The two groups (rejected and accepted) will have different colors. (2.5 hours)

2. Is there a tendency for specific loans to be given during a specific months? To answer this, a rose plot will be constructed using the twelve months. The legend will represent the top five most frequent loans. Each loan will have a unique color. (1.5 hours)

3. What is the frequency of accepted and rejected loans throughout the United States? To answer this, a map using geospatial data of the U.S. will plotted and matched with the first three digits of the applicant's zip code. A map using the states can also be built, but the main visual will use the zip code. Two graphs will be made splitting rejected and accepted applicants. The frequency will be recorded as a single gradient of a color with a higher count representing a darker gradient. A legend will be provided to indicate the gradient and the number that the different colors represent. (3.5 hours)

4. Does the ratio of amount funded to amount requested change based on hardship flag, home ownership, and application type? To answer this, I will build a tree diagram that builds branches based on the outcome of the three chosen columns. Each level of the tree will be colored differently. The results of the tree will be inputted as the average of the grouped ratios. (3 hours)

5. Does an applicant's FICO score change the interest rate they receive? What about the funding-requested ratio? To answer this, an area chart will be used to measure the count of applicants and split by their FICO score grouping. The x-axis will be either the interest rate or funding-requested ratio. Their will be two graphs, one for each x-axis variable. The FICO score groups will each have their own color along a single gradient and a legend will specify. (3 hours)

6. Is there a bound to Debt-To-Income ratio so that customers who are below a certain limit cannot be accepted? To answer this, a histogram will be built to represent the DTI ratio of both rejected and accepted applicants. If there is a noticeable drop in acceptance, that observation may indicate a minimum acceptance. (1.5 hours)

7. Using the matching features between accepted and rejected data, is it possible to effectively predict whether a candidate will be accepted or rejected? Three supervised machine learning models will be used to find the models accuracy, precision, and recall. With accepted being labeled ones and rejected zeroes, the goal is to identify the most applicants for acceptance while focusing on minimizing the false positives over false negatives. The three models to be used are KNN, Decision Tree, and Random Forests. A third ensemble method will be used that uses hard voting to classify. (7 hours)

# Work plan

**Week 4 (2/6 - 2/12):**

* Data tidying and recoding (6 hours).
* Question 6 (1.5 hours).

**Week 5 (2/13 - 2/19):**

* Question 3 (3.5 hours).
* Question 1 (2.5 hours).
* Question 2 (1.5 hours).

**Week 6 (2/20 - 2/26):**

* Question 4 (3 hours).
* Question 5 (3 hours).
* Begin to outline presentation, assess status of project (1 hour).

**Week 7 (2/27 - 3/5):**

* Question 7 (7 hours).

**Week 8 (3/6 - 3/12):** *Presentations in class on Thurs 3/9.*

* Presentation prep and practice (4 hours).
* Presentation peer review (1.5 hours).
* Assess status of project. If time allows, add ethical aspect about Zip Codes. (1.5 hour).
* Begin drafting report (0.5 hour).

**Week 9 (3/20 - 3/26):**

* Clean up code, add any needed comments, and make sure the git repository looks professional (3 hours).
* Poster prep (4 hours).

**Week 10 (3/27 - 4/2):** *Poster Draft 1 due Monday 3/27*.
*Peer feedback due Thursday 3/30*.

* Continue writing report (2.5 hours).
* Peer feedback (2.5 hours).
* Poster revisions (2 hours).

**Week 11 (4/3 - 4/9):** *Poster Draft 2 due Monday 4/3*.
*Final Poster due Saturday 4/8*.

* Double-checking organization of files in git repository (1 hour).
* Research the possibility of embedding animations of graphs inside blog post (2 hours).
* Poster revisions (4 hour).

**Week 12 (4/10 - 4/16):**

* Continue drafting blog post (7 hours)

**Week 13 (4/17 - 4/23):** 

* Continue drafting blog post (7 hours).

**Week 14 (4/24 - 4/30):** *Blog post draft 1 due Monday 4/24. Peer feedback due Thursday 4/27. Blog post draft 2 due Sunday 4/30*. 

* Peer feedback (2.5 hours)
* Blog post revisions (2 hours)

**Week 15 (5/1 - 5/7):**  *Final blog post due Tuesday 5/2*.

* Final presentation prep and practice (7 hours).

**Final Exam Week (5/8):** *Final Presentations during final exam slot, Monday May 9th 3:20-6:40pm.* 

# References

